{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b19cd29",
   "metadata": {},
   "source": [
    "# LLMS for NASA PDS!\n",
    "\n",
    "The goal of this notebook is to introduce you all to the use of LLMs as a search tool for the NASA Planetary Data system. You will call and use your own API key for a custom LLM deployment. \n",
    "\n",
    "In this notebook, we will be working with the old, soon deprecated version of PDS, Atlas III. However, the concepts are still relevant to Atlas IV, which will be our use-case for this project. Follow [this link](https://pds-imaging.jpl.nasa.gov/search/?fq=-ATLAS_THUMBNAIL_URL%3Abrwsnotavail.jpg&q=*%3A*) to navigate to the Atlas III website. It should look like this: \n",
    "\n",
    "![Atlas III screenshot](data/atlas_3_screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c908acc9",
   "metadata": {},
   "source": [
    "Lots of filters on that site, huh? It might be fine for those who know about the facets (and therefore know what they are looking for), but it might not be the most accessible option. What if we were to use the search box at the top? Let's say I was a researcher who wanted to find images of 'Swiss Cheese' and 'Dark Dune' on Mars. Let's also assume in this scenario that I somehow don't know how to use the filters, so I try the search bar instead. I type in \"swiss cheese and dark dunes\" and get the following as a result: \n",
    "\n",
    "![Atlas III Search](data/atlas_3_search.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fcc4b6",
   "metadata": {},
   "source": [
    "Not very helpful, isn't it? Thankfully, for a query such as this, we can simply select the filters on the left hand side under 'MRO HiRISE Image Landmarks' and select the relevant facets, so the desired images do in fact exist on the website -- the search bar just doesn't support. This brings our use-case for LLMs; **can they serve as a useful search assistant for the PDS website?**? LLMs make a good candidate for this use case, because of the fact that LLMs work well with unstructured, natural human language, and have a better ability to recognize the nuance in language. After all, no scientist is literally looking for \"Swiss Cheese\" on Mars - it is a specific term used to describe a unique terrain on the planet's polar ice cap. \n",
    "\n",
    "We can demonstrate the potential for LLMs by creating our own chatbot using the OLMo model from the Allen Institute for AI. You don't need to worry too much about calling LLMs through APIs, as we will discuss this later on :) For now, follow these instructions: \n",
    "\n",
    "Click on [this link](https://openrouter.ai/allenai/olmo-3.1-32b-think) to the OpenRouter website.\n",
    "\n",
    "Scroll down to where it says \"Create API key\" and click on it. It should look like this: \n",
    "\n",
    "![Create API key](data/create_api.png)\n",
    "\n",
    "Sign in with your GitHub, Gmail, or whatever you choose. Once you've done that, click on \"Create\" and give your API key a title. \n",
    "\n",
    "![Create Key](data/create_key.png)\n",
    "\n",
    "Once you've done that, **be sure to copy and paste your key!!** You will NOT be able to access it again. \n",
    "\n",
    "![Key Created](data/new_key.png)\n",
    "\n",
    "In order to securely use your API key in your workspace, you will need to create a .env file at the workspace root. I have already include an example.env file at this workspace root - all you need to do is to change the name to \".env\" only, and paste your API key where indicated. I've already added the `.env` file to the `.gitignore`, so it won't be pushed onto the main site. \n",
    "\n",
    "Now that that's all settled, **let's get started with creating our beta chatbot with OLMO!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e0ed26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not os.getenv(\"OPENROUTER_API_KEY\"):\n",
    "    raise ValueError(\"Missing OPENROUTER_API_KEY. Set it in your .env file.\")\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1137c7",
   "metadata": {},
   "source": [
    "## Part 1: LLM only (no retrieval)\n",
    "\n",
    "In this first pass, we ask the model to map a natural-language query to likely Atlas III facets.\n",
    "This is intentionally naive so we can compare it to RAG later.\n",
    "\n",
    "**Output format:** a short JSON-like list of suggested facets, plus a one-sentence rationale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eee30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swiss cheese, dark dune\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"allenai/olmo-3.1-32b-think\"\n",
    "\n",
    "# A system prompt is a set of instructions that guides the behavior of the language model. \n",
    "# It helps the model understand the context and the expected output format for a given task. \n",
    "# In this case, the system prompt instructs the model to act as a PDS search assistant for Atlas III \n",
    "# and to return relevant filters based on user queries about Mars images.\n",
    "\n",
    "BASELINE_SYSTEM_PROMPT = \"\"\"\n",
    "You are a PDS search assistant for Atlas III.\n",
    "Given a user query, return the relevant filter one of the following:\n",
    "\n",
    "Bright dune, crater, dark dune, other, slope streak, impact ejecta, spider, swiss cheese.\n",
    "\"\"\"\n",
    "\n",
    "def ask_llm_only(query):\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": BASELINE_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "query = \"Find Mars images of swiss cheese terrain and dark dunes.\"\n",
    "print(ask_llm_only(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ebb5ac",
   "metadata": {},
   "source": [
    "## Part 2: Simple RAG over landform classes\n",
    "\n",
    "Now we ground the model with a tiny retrieval step using a short list of landform classes in `tutorial/landform_classes.txt`.\n",
    "This keeps the RAG example focused and easy to follow.\n",
    "\n",
    "Try a few queries like:\n",
    "- \"Find swiss cheese terrain near the south polar region.\"\n",
    "- \"I want images of dark dunes and impact ejecta.\"\n",
    "- \"Show me slope streaks on Mars.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d3fd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"suggestions\": [\n",
      "    {\n",
      "      \"class\": \"Swiss cheese\",\n",
      "      \"reason\": \"Terrain with pits formed by sublimation of ice.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def normalize(text):\n",
    "    return re.findall(r\"[a-z0-9]+\", text.lower())\n",
    "\n",
    "# This is the context for the LLM to use in the RAG approach. It is built from the landform classes and their descriptions.\n",
    "# Sort of like a \"reference page\" so the model can stick to the domain-specific info and not hallucinate based on its training data.\n",
    "\n",
    "def load_landform_classes(path=\"tutorial/landform_classes.txt\"):\n",
    "    classes = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            if \":\" not in line:\n",
    "                continue\n",
    "            name, desc = line.split(\":\", 1)\n",
    "            classes.append({\n",
    "                \"name\": name.strip(),\n",
    "                \"description\": desc.strip(),\n",
    "            })\n",
    "    return classes\n",
    "\n",
    "# basic lotic for formatting the landorm classes \n",
    "\n",
    "def build_docs(classes):\n",
    "    docs = []\n",
    "    for item in classes:\n",
    "        text = f\"{item['name']} {item['description']}\"\n",
    "        tokens = set(normalize(text))\n",
    "        docs.append({\n",
    "            \"name\": item[\"name\"],\n",
    "            \"description\": item[\"description\"],\n",
    "            \"tokens\": tokens,\n",
    "        })\n",
    "    return docs\n",
    "\n",
    "# this function retrieves the most relevant landform classes based on token overlap with the query. \n",
    "# It's a simple bag-of-words approach, but it helps the LLM focus on the most relevant context when we do RAG.\n",
    "\n",
    "def retrieve(query, docs, top_k=4):\n",
    "    q_tokens = Counter(normalize(query))\n",
    "    scored = []\n",
    "    for doc in docs:\n",
    "        score = sum(q_tokens[t] for t in doc[\"tokens\"] if t in q_tokens)\n",
    "        if score > 0:\n",
    "            scored.append((score, doc))\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    return [doc for _, doc in scored[:top_k]]\n",
    "\n",
    "def format_context(docs):\n",
    "    parts = []\n",
    "    for doc in docs:\n",
    "        parts.append(f\"Class: {doc['name']} | Description: {doc['description']}\")\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "# this is the new instruction set, telling the LLM to use the retrieved context to make a more informed suggestion about the landform class.\n",
    "\n",
    "RAG_SYSTEM_PROMPT = \"\"\"\n",
    "You are a PDS search assistant for Atlas III.\n",
    "Use ONLY the provided context to suggest landform classes.\n",
    "Return a JSON-like list with objects: {class, reason}.\n",
    "If the context is insufficient, say you need more info.\n",
    "\"\"\"\n",
    "\n",
    "classes = load_landform_classes()\n",
    "docs = build_docs(classes)\n",
    "\n",
    "def ask_llm_rag(query):\n",
    "    top_docs = retrieve(query, docs, top_k=4)\n",
    "    context = format_context(top_docs)\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": RAG_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuery: {query}\"},\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "query = \"Find swiss cheese terrain near the south polar region.\"\n",
    "print(ask_llm_rag(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af252e7",
   "metadata": {},
   "source": [
    "## Part 2b: Implicit class queries (why RAG helps)\n",
    "\n",
    "Some queries never mention a class name directly. For example, a user might describe a feature (\"defrosted dunes\") without saying \"dark dune.\"\n",
    "The RAG context lets the model map those implicit descriptions to the closest class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd89d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Images of defrosted dunes on Mars\n",
      "LLM only:\n",
      "[\n",
      "  { \"facet\": \"Celestial Body\", \"value\": \"Mars\", \"reason\": \"Query specifies Mars as the location.\" },\n",
      "  { \"facet\": \"Feature Type\", \"value\": \"Dunes\", \"reason\": \"Query explicitly mentions 'dunes' as the subject.\" },\n",
      "  { \"facet\": \"Season\", \"value\": \"Spring\", \"reason\": \"Defrosting occurs during Martian spring due to CO2 sublimation.\" },\n",
      "  { \"facet\": \"Location\", \"value\": \"Polar Regions\", \"reason\": \"Defrosted dunes are common in Martian polar areas with seasonal CO2 ice.\" }\n",
      "]\n",
      "RAG:\n",
      "{\n",
      "  \"suggestions\": [\n",
      "    {\n",
      "      \"class\": \"Dark dune\",\n",
      "      \"reason\": \"The context explicitly defines 'Dark dune' as dunes that are completely defrosted on Mars, directly matching the query's focus on 'defrosted dunes.'\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "----------------------------------------\n",
      "Query: Pits formed by ice sublimation near the poles\n",
      "LLM only:\n",
      "[\n",
      "  { \"facet\": \"Planet\", \"value\": \"Mars\", \"reason\": \"Sublimation pits are commonly observed in Martian polar regions.\" },\n",
      "  { \"facet\": \"Feature Type\", \"value\": \"Sublimation Pits\", \"reason\": \"Directly matches the described geological formation.\" },\n",
      "  { \"facet\": \"Formation Process\", \"value\": \"Sublimation\", \"reason\": \"Process explicitly mentioned in the query.\" },\n",
      "  { \"facet\": \"Location\", \"value\": \"Polar Regions\", \"reason\": \"Query specifies formation near planetary poles.\" }\n",
      "]\n",
      "RAG:\n",
      "{\n",
      "  \"suggestions\": [\n",
      "    {\n",
      "      \"class\": \"Swiss cheese\",\n",
      "      \"reason\": \"Pits formed by ice sublimation directly match the description of the Swiss cheese class, which is defined as terrain with pits from this process.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "----------------------------------------\n",
      "Query: Dark flow-like features on slopes\n",
      "LLM only:\n",
      "[\n",
      "  {\"facet\": \"Feature Type\", \"value\": \"Landslide\", \"reason\": \"Flow-like movement on slopes is characteristic of landslides.\"},\n",
      "  {\"facet\": \"Feature Type\", \"value\": \"Debris Flow\", \"reason\": \"Debris flows produce flow-like features with mixed materials.\"},\n",
      "  {\"facet\": \"Color\", \"value\": \"Dark\", \"reason\": \"Query specifies 'dark', indicating low reflectance or dark material.\"},\n",
      "  {\"facet\": \"Process\", \"value\": \"Mass Movement\", \"reason\": \"Flow-like features typically result from gravitational mass movement.\"}\n",
      "]\n",
      "RAG:\n",
      "{\n",
      "  \"suggestions\": [\n",
      "    {\n",
      "      \"class\": \"Slope streak\",\n",
      "      \"reason\": \"The query describes 'dark flow-like features on slopes,' which directly matches the definition of a 'Slope streak' as a feature formed by such characteristics.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "implicit_queries = [\n",
    "    \"Images of defrosted dunes on Mars\",\n",
    "    \"Pits formed by ice sublimation near the poles\",\n",
    "    \"Dark flow-like features on slopes\",\n",
    "]\n",
    "\n",
    "for q in implicit_queries:\n",
    "    print(\"Query:\", q)\n",
    "    print(\"LLM only:\")\n",
    "    print(ask_llm_only(q))\n",
    "    print(\"RAG:\")\n",
    "    print(ask_llm_rag(q))\n",
    "    print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
