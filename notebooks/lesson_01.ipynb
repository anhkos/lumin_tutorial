{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b19cd29",
   "metadata": {},
   "source": [
    "# LLMS for NASA PDS!\n",
    "\n",
    "The goal of this notebook is to introduce you all to the use of LLMs as a search tool for the NASA Planetary Data system. You will call and use your own API key for a custom LLM deployment. \n",
    "\n",
    "In this notebook, we will be working with the old, soon deprecated version of PDS, Atlas III. However, the concepts are still relevant to Atlas IV, which will be our use-case for this project. Follow [this link](https://pds-imaging.jpl.nasa.gov/search/?fq=-ATLAS_THUMBNAIL_URL%3Abrwsnotavail.jpg&q=*%3A*) to navigate to the Atlas III website. It should look like this: \n",
    "\n",
    "![Atlas III screenshot](../data/atlas_3_screenshot.png)\n",
    "\n",
    "Lots of filters on that site, huh? It might be fine for those who know about the facets (and therefore know what they are looking for), but it might not be the most accessible option. What if we were to use the search box at the top? Let's say I was a researcher who wanted to find images of 'Swiss Cheese' and 'Dark Dune' on Mars. Let's also assume in this scenario that I somehow don't know how to use the filters, so I try the search bar instead. I type in \"swiss cheese and dark dunes\" and get the following as a result: \n",
    "\n",
    "![Atlas III Search](../data/atlas_3_search.png)\n",
    "\n",
    "Not very helpful, isn't it? Thankfully, for a query such as this, we can simply select the filters on the left hand side under 'MRO HiRISE Image Landmarks' and select the relevant facets, so the desired images do in fact exist on the website -- the search bar just doesn't support. This brings our use-case for LLMs; **can they serve as a useful search assistant for the PDS website?**? LLMs make a good candidate for this use case, because of the fact that LLMs work well with unstructured, natural human language, and have a better ability to recognize the nuance in language. After all, no scientist is literally looking for \"Swiss Cheese\" on Mars - it is a specific term used to describe a unique terrain on the planet's polar ice cap. \n",
    "\n",
    "We can demonstrate the potential for LLMs by creating our own chatbot using the OLMo model from the Allen Institute for AI. You don't need to worry too much about calling LLMs through APIs, as we will discuss this later on :) For now, follow these instructions: \n",
    "\n",
    "Click on [this link](https://openrouter.ai/allenai/olmo-3.1-32b-think) to the OpenRouter website.\n",
    "\n",
    "Scroll down to where it says \"Create API key\" and click on it. It should look like this: \n",
    "\n",
    "![Create API key](../data/create_api.png)\n",
    "\n",
    "Sign in with your GitHub, Gmail, or whatever you choose. Once you've done that, click on \"Create\" and give your API key a title. \n",
    "\n",
    "![Create Key](../data/create_key.png)\n",
    "\n",
    "Once you've done that, **be sure to copy and paste your key!!** You will NOT be able to access it again. \n",
    "\n",
    "![Key Created](../data/new_key.png)\n",
    "\n",
    "In order to securely use your API key in your workspace, you will need to create a .env file at the workspace root. I have already include an example.env file at this workspace root - all you need to do is to change the name to \".env\" only, and paste your API key where indicated. I've already added the `.env` file to the `.gitignore`, so it won't be pushed onto the main site. \n",
    "\n",
    "Now that that's all settled, **let's get started with creating our beta chatbot with OLMO!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e0ed26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not os.getenv(\"OPENROUTER_API_KEY\"):\n",
    "    raise ValueError(\"Missing OPENROUTER_API_KEY. Set it in your .env file.\")\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1137c7",
   "metadata": {},
   "source": [
    "## Part 1: LLM only (no retrieval)\n",
    "\n",
    "In this first pass, we ask the model to map a natural-language query to likely Atlas III facets.\n",
    "\n",
    "The output given the query will just be a return list of filters. Feel free to saw out the query variable and try a few queries like:\n",
    "- \"Find swiss cheese terrain near the south polar region.\"\n",
    "- \"I want images of dark dunes and impact ejecta.\"\n",
    "- \"Show me slope streaks on Mars.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eee30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swiss cheese, dark dune\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"allenai/olmo-3.1-32b-think\"\n",
    "\n",
    "# A system prompt is a set of instructions that guides the behavior of the language model. \n",
    "# It helps the model understand the context and the expected output format for a given task. \n",
    "# In this case, the system prompt instructs the model to act as a PDS search assistant for Atlas III \n",
    "# and to return relevant filters based on user queries about Mars images.\n",
    "\n",
    "BASELINE_SYSTEM_PROMPT = \"\"\"\n",
    "You are a PDS search assistant for Atlas III.\n",
    "Given a user query, return the relevant filter one of the following:\n",
    "\n",
    "Bright dune, crater, dark dune, other, slope streak, impact ejecta, spider, swiss cheese.\n",
    "\"\"\"\n",
    "\n",
    "def ask_llm_only(query):\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": BASELINE_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "query = \"Find Mars images of swiss cheese terrain and dark dunes.\"\n",
    "print(ask_llm_only(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ebb5ac",
   "metadata": {},
   "source": [
    "## Part 2: Simple RAG over landform classes\n",
    "\n",
    "In that first example, you saw that the model saw the query, and most likely reasoned that the relevant filters were \"swiss cheese\" and \"dark dune\", which is correct! If you swapped out some of the queries, how did it do? Was it better or worse than the search engine on the PDS site? \n",
    "\n",
    "We're already doing much better than our original example, but might raise the question/thought of \"but this is just doing the same thing a traditional search engine could do. Aren't we cracking a nut with a sledgehammer here by using an LLM?\"\n",
    "\n",
    "This would be correct, as most traditional search engines (like that of Google's) should be able to handle such queries where the key words are already present. Heck, even a simple regex-matching program might even do. If we were only concerned with simple queries that had the keywords present, then it would be a waste to use the computational power of a large language model. \n",
    "\n",
    "The problem with planetary science archives like PDS is that users may not know the exact names of the keywords that they need to search. What if a scientist, intending to find images of  on Mars but doesn't know that \n",
    "\n",
    "Now we ground the model with a tiny retrieval step using a short list of landform classes in `tutorial/landform_classes.txt`.\n",
    "This keeps the RAG example focused and easy to follow.\n",
    "\n",
    "Try a few queries like:\n",
    "- \"Find swiss cheese terrain near the south polar region.\"\n",
    "- \"I want images of dark dunes and impact ejecta.\"\n",
    "- \"Show me slope streaks on Mars.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d3fd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"results\": [\n",
      "    {\n",
      "      \"class\": \"Swiss cheese\",\n",
      "      \"reason\": \"The query explicitly requests 'Swiss cheese terrain', which is a defined class characterized by pits formed by sublimation of ice. The context does not exclude this class from the south polar region.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def normalize(text):\n",
    "    return re.findall(r\"[a-z0-9]+\", text.lower())\n",
    "\n",
    "# This is the context for the LLM to use in the RAG approach. It is built from the landform classes and their descriptions.\n",
    "# Sort of like a \"reference page\" so the model can stick to the domain-specific info and not hallucinate based on its training data.\n",
    "\n",
    "def load_landform_classes(path=\"data/landform_classes.txt\"):\n",
    "    classes = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            if \":\" not in line:\n",
    "                continue\n",
    "            name, desc = line.split(\":\", 1)\n",
    "            classes.append({\n",
    "                \"name\": name.strip(),\n",
    "                \"description\": desc.strip(),\n",
    "            })\n",
    "    return classes\n",
    "\n",
    "# basic lotic for formatting the landorm classes \n",
    "\n",
    "def build_docs(classes):\n",
    "    docs = []\n",
    "    for item in classes:\n",
    "        text = f\"{item['name']} {item['description']}\"\n",
    "        tokens = set(normalize(text))\n",
    "        docs.append({\n",
    "            \"name\": item[\"name\"],\n",
    "            \"description\": item[\"description\"],\n",
    "            \"tokens\": tokens,\n",
    "        })\n",
    "    return docs\n",
    "\n",
    "# this function retrieves the most relevant landform classes based on token overlap with the query. \n",
    "# It's a simple bag-of-words approach, but it helps the LLM focus on the most relevant context when we do RAG.\n",
    "\n",
    "def retrieve(query, docs, top_k=4):\n",
    "    q_tokens = Counter(normalize(query))\n",
    "    scored = []\n",
    "    for doc in docs:\n",
    "        score = sum(q_tokens[t] for t in doc[\"tokens\"] if t in q_tokens)\n",
    "        if score > 0:\n",
    "            scored.append((score, doc))\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    return [doc for _, doc in scored[:top_k]]\n",
    "\n",
    "def format_context(docs):\n",
    "    parts = []\n",
    "    for doc in docs:\n",
    "        parts.append(f\"Class: {doc['name']} | Description: {doc['description']}\")\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "# this is the new instruction set, telling the LLM to use the retrieved context to make a more informed suggestion about the landform class.\n",
    "\n",
    "RAG_SYSTEM_PROMPT = \"\"\"\n",
    "You are a PDS search assistant for Atlas III.\n",
    "Use ONLY the provided context to suggest landform classes.\n",
    "Return a JSON-like list with objects: {class, reason}.\n",
    "If the context is insufficient, say you need more info.\n",
    "\"\"\"\n",
    "\n",
    "classes = load_landform_classes()\n",
    "docs = build_docs(classes)\n",
    "\n",
    "def ask_llm_rag(query):\n",
    "    top_docs = retrieve(query, docs, top_k=4)\n",
    "    context = format_context(top_docs)\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": RAG_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuery: {query}\"},\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "query = \"Find swiss cheese terrain near the south polar region.\"\n",
    "print(ask_llm_rag(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af252e7",
   "metadata": {},
   "source": [
    "## Part 2b: Implicit class queries (why RAG helps)\n",
    "\n",
    "Some queries never mention a class name directly. For example, a user might describe a feature (\"defrosted dunes\") without saying \"dark dune.\"\n",
    "The RAG context lets the model map those implicit descriptions to the closest class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd89d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Images of defrosted dunes on Mars\n",
      "LLM only:\n",
      "dark dune\n",
      "RAG:\n",
      "{\n",
      "  \"suggestions\": [\n",
      "    {\n",
      "      \"class\": \"Dark dune\",\n",
      "      \"reason\": \"The context explicitly defines 'Dark dune' as 'Dunes that are completely defrosted on Mars,' which directly matches the query's focus on 'defrosted dunes.'\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "----------------------------------------\n",
      "Query: Pits formed by ice sublimation near the poles\n",
      "LLM only:\n",
      "swiss cheese\n",
      "RAG:\n",
      "{\n",
      "  \"suggestions\": [\n",
      "    {\n",
      "      \"class\": \"Swiss cheese\",\n",
      "      \"reason\": \"Terrain with pits formed by sublimation of ice directly matches the description of pits formed by ice sublimation near the poles.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "----------------------------------------\n",
      "Query: Dark flow-like features on slopes\n",
      "LLM only:\n",
      "slope streak\n",
      "RAG:\n",
      "{\n",
      "  \"suggestions\": [\n",
      "    {\n",
      "      \"class\": \"Slope streak\",\n",
      "      \"reason\": \"The context explicitly describes 'Slope streak' as features formed by dark flow-like features on slopes, directly matching the query's description.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "implicit_queries = [\n",
    "    \"Images of defrosted dunes on Mars\",\n",
    "    \"Pits formed by ice sublimation near the poles\",\n",
    "    \"Dark flow-like features on slopes\",\n",
    "]\n",
    "\n",
    "for q in implicit_queries:\n",
    "    print(\"Query:\", q)\n",
    "    print(\"LLM only:\")\n",
    "    print(ask_llm_only(q))\n",
    "    print(\"RAG:\")\n",
    "    print(ask_llm_rag(q))\n",
    "    print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
